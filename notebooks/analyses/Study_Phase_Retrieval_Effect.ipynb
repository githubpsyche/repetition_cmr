{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Study Phase Retrieval Effect\n",
    "They considered transitions between items following a shared repeated item. They calculated the proportion of those items recalled in $S_j = {j + 1, j + 2}$ of which CMR then recalled an item in the set $S_i = {i + 1, i + 2}$. They also calculated the proportion of recalls $S_i$ of which CMR then transitioned to an item in the set $S_j$. They calculated the proportion of transitions for each of lags $j - i >= 4$, and represented the mean percent of transitions across these lags. \n",
    "\n",
    "We'll extend this analysis by performing a masked, reference-shifted lag-crp analysis. We'll only track transitions from neighbors of repeatedly-presented items. And we'll shift our lag-reference from the these items to the alternative position of the repeatedly-presented items they transitioned from.\n",
    "\n",
    "To estimate the proportion of transitions that CMR would make at these lags in the absence of repeated items, they considered transitions in control lists matched to the same serial positions considered in the mixed lists. They matched these serial positions to 100 random shuffles of the control lists, and took the mean across the reshuffled datasets. We'll develop that functionality elsewhere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "We start with a specification of `picky_lag_crp` that supports item repetitions. Then we need to write a mask that selects transitions from items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from repetition_cmr.analyses import recall_by_all_study_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "from numba import njit\n",
    "import numpy as np\n",
    "\n",
    "#@njit(nogil=True)\n",
    "def neighbor_contiguity(trials, presentations, max_repeats=2):\n",
    "    \n",
    "    list_length = len(presentations[0])\n",
    "    lag_range = list_length - 1\n",
    "    total_actual_lags = np.zeros(lag_range * 2 + 1)\n",
    "    total_possible_lags = np.zeros(lag_range * 2 + 1)\n",
    "    terminus = np.sum(trials != 0, axis=1) # number of recalls per trial\n",
    "    recall_by_study_position = recall_by_all_study_positions(trials, presentations, max_repeats)\n",
    "    trials_shape = np.shape(trials)\n",
    "    mask = np.zeros((trials_shape[0], max_repeats, trials_shape[1]), dtype=np.bool_)\n",
    "    reference_positions = np.zeros((trials_shape[0], max_repeats, trials_shape[1]), dtype=np.int32)\n",
    "\n",
    "    for trial_index, presentation in enumerate(presentations):\n",
    "\n",
    "        masked_items = [[] for _ in range(max_repeats)]\n",
    "\n",
    "        for current_index, current_item in enumerate(presentation[:-1]):\n",
    "\n",
    "            # identify each time current_item occurs in presentation and skip if count is 1\n",
    "            positions = np.nonzero(presentation == current_item)[0]\n",
    "            if len(positions) == 1:\n",
    "                continue\n",
    "\n",
    "            # also skip if lag between positions is <4\n",
    "            if positions[1] - positions[0] < 4:\n",
    "                continue\n",
    "\n",
    "            # identify relative position of current_index in repetitions\n",
    "            repetition_index = np.nonzero(positions==current_index)[0][0]\n",
    "\n",
    "            # recall of item at succesive two serial positions should be in mask \n",
    "            # reference_positions position should be the repetition position that's distinct from current_index\n",
    "            # TODO: figure out policy for when max_repeats > 2\n",
    "            if current_index+1 < list_length:\n",
    "                masked_items[repetition_index].append(presentation[current_index+1]+1)\n",
    "\n",
    "                reference_positions[trial_index, repetition_index, np.nonzero(\n",
    "                    trials[trial_index] == presentation[current_index+1]+1)[0]] = positions[positions != current_index][0] + 1\n",
    "\n",
    "            if current_index+2 < list_length:\n",
    "                masked_items[repetition_index].append(presentation[current_index+2]+1)\n",
    "\n",
    "                reference_positions[trial_index, repetition_index, np.nonzero(\n",
    "                    trials[trial_index] == presentation[current_index+2]+1)[0]] = positions[positions != current_index][0] + 1    \n",
    "\n",
    "        for i in range(max_repeats):\n",
    "            mask[trial_index, i] = np.isin(trials[trial_index], np.array(masked_items[i]))\n",
    "\n",
    "        # if trial_index == 0:\n",
    "        #     print(presentation)\n",
    "        #     print(trials[trial_index]-1)\n",
    "        #     print(mask[trial_index])\n",
    "        #     print(reference_positions[trial_index])\n",
    "        #assert(False)\n",
    "        \n",
    "    for trial_index in range(len(trials)):\n",
    "        \n",
    "        previous_item = 0\n",
    "        item_count = np.max(presentations[trial_index]) + 1\n",
    "        possible_items = np.arange(item_count) # initial pool of possible recalls, 1-indexed\n",
    "        possible_positions = np.zeros((item_count, max_repeats), dtype=np.int32)\n",
    "        \n",
    "        # we track possible positions using presentations and alt_presentations\n",
    "        for item in range(item_count):\n",
    "            pos = np.nonzero(presentations[trial_index] == item)[0] + 1\n",
    "            possible_positions[item, :len(pos)] = pos\n",
    "            \n",
    "        for recall_index in range(terminus[trial_index]):\n",
    "            \n",
    "            current_item = presentations[trial_index][trials[trial_index, recall_index]-1]\n",
    "            \n",
    "            # track possible and actual lags\n",
    "            # TODO: add mask condition to select only transitions from Si and Sj\n",
    "            if recall_index > 0 and np.any(mask[trial_index, :, recall_index-1]): \n",
    "\n",
    "                repetition_index = np.nonzero(mask[trial_index, :, recall_index-1])[0][0]\n",
    "                \n",
    "                # item indices don't help track lags anymore\n",
    "                # so more complex calculation needed to identify possible lags given previous item\n",
    "                current_index = np.nonzero(possible_items==current_item)[0]\n",
    "                possible_lags = np.zeros((max_repeats, len(possible_items)), dtype=np.int32)\n",
    "\n",
    "                for x in range(len(recall_by_study_position)):\n",
    "                    # for y in range(len(recall_by_study_position)):\n",
    "                    #     if reference_positions[trial_index, y, recall_index-1] > 0:\n",
    "                        \n",
    "                    possible_lags[x] = possible_positions[\n",
    "                        possible_items, x] - reference_positions[trial_index, repetition_index, recall_index-1]\n",
    "                    \n",
    "                    # if tracked position is 0, then we don't actually want to count it in our lags\n",
    "                    possible_lags[x][possible_positions[possible_items, x] == 0] = 0\n",
    "\n",
    "                possible_lags += lag_range\n",
    "                total_actual_lags[possible_lags[:, current_index].flatten()] += 1\n",
    "                total_possible_lags[possible_lags.flatten()] += 1\n",
    "\n",
    "            # update pool to exclude recalled item (updated to still identify 1-indexed item)\n",
    "            previous_item = current_item\n",
    "            possible_items = possible_items[possible_items != previous_item]\n",
    "                    \n",
    "    # small correction to avoid nans and commit to excluding multiply-tracked single presentations \n",
    "    total_actual_lags[lag_range] = 0\n",
    "    total_possible_lags[total_actual_lags==0] += 1\n",
    "    \n",
    "    return total_actual_lags/total_possible_lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169.0 2530.0\n",
      "[0.         0.         0.         0.07142857 0.07317073 0.01538462\n",
      " 0.03409091 0.02608696 0.01333333 0.03825137 0.02202643 0.01123596\n",
      " 0.01286174 0.02432432 0.01690821 0.01046025 0.02702703 0.01584507\n",
      " 0.01771337 0.01783061 0.03034483 0.0405954  0.03090235 0.01853998\n",
      " 0.03179825 0.04115226 0.03519062 0.04919584 0.05028463 0.0480226\n",
      " 0.07276119 0.06540284 0.09235075 0.08340573 0.08065915 0.05922166\n",
      " 0.06193969 0.05942948 0.06942278 0.         0.07097289 0.06269592\n",
      " 0.05414013 0.05823627 0.05602007 0.05681818 0.0460251  0.03169308\n",
      " 0.03022453 0.04181185 0.0380868  0.02982293 0.02364532 0.02651113\n",
      " 0.03097345 0.02719407 0.0129199  0.0210084  0.02391629 0.0192\n",
      " 0.02166065 0.015625   0.01594533 0.0255102  0.01428571 0.00680272\n",
      " 0.01321586 0.01685393 0.         0.01834862 0.02597403 0.\n",
      " 0.025      0.         0.         0.         0.         0.\n",
      " 0.        ]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy.matlib\n",
    "from compmemlearn.datasets import events_metadata, generate_trial_mask\n",
    "\n",
    "events = pd.read_csv('../../../compmemlearn/data/LohnasKahana2014.csv')\n",
    "trials, list_lengths, presentations = events_metadata(events)\n",
    "trials = trials\n",
    "presentations = presentations\n",
    "list_length = list_lengths\n",
    "\n",
    "\n",
    "for condition in [4]:\n",
    "    trial_mask = generate_trial_mask(events, f\"condition == {condition}\")[0]\n",
    "    print(neighbor_contiguity(trials[0][trial_mask], presentations[0][trial_mask]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ecf5722fdaf1897a315d257d89d94520bfcaa453217d5becf09b39e73618b0de"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
