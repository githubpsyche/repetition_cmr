{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe182068-7a11-4ad9-bf76-197303104d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abba0af-43f5-4278-ac78-a7d274a61fe5",
   "metadata": {},
   "source": [
    "## Trace-Based Reinstatement\n",
    "A variant of InstanceCMR that slightly breaks PrototypeCMR's assumption that feature-to-context associations drive the evolution of context across a list-learning experiment. Instead, we'll suppose that a composite cue containing activation of an item's item-feature unit AND main contextual unit determines contextual input at each model step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e0bcb9-973d-4314-899d-98689d79a249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "\n",
    "import numpy as np\n",
    "from numba import float64, int32, boolean\n",
    "from numba.experimental import jitclass\n",
    "\n",
    "trcmr_spec = [\n",
    "    ('item_count', int32), \n",
    "    ('encoding_drift_rate', float64),\n",
    "    ('start_drift_rate', float64),\n",
    "    ('recall_drift_rate', float64),\n",
    "    ('delay_drift_rate', float64),\n",
    "    ('shared_support', float64),\n",
    "    ('item_support', float64),\n",
    "    ('learning_rate', float64),\n",
    "    ('primacy_scale', float64),\n",
    "    ('primacy_decay', float64),\n",
    "    ('stop_probability_scale', float64),\n",
    "    ('stop_probability_growth', float64),\n",
    "    ('choice_sensitivity', float64),\n",
    "    ('context_sensitivity', float64),\n",
    "    ('feature_sensitivity', float64),\n",
    "    ('context', float64[::1]),\n",
    "    ('start_context_input', float64[::1]),\n",
    "    ('delay_context_input', float64[::1]),\n",
    "    ('preretrieval_context', float64[::1]),\n",
    "    ('recall', int32[::1]),\n",
    "    ('retrieving', boolean),\n",
    "    ('recall_total', int32),\n",
    "    ('item_weighting', float64[::1]),\n",
    "    ('context_weighting', float64[::1]),\n",
    "    ('all_weighting', float64[::1]),\n",
    "    ('probabilities', float64[::1]),\n",
    "    ('memory', float64[:,::1]),\n",
    "    ('encoding_index', int32),\n",
    "    ('items', float64[:,::1]),\n",
    "    ('recall_items', float64[:,::1]),\n",
    "    ('norm', float64[::1]),\n",
    "    ('context_reinstatement', float64),\n",
    "    ('feature_drift_rate', float64),\n",
    "    ('features', float64[::1]),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5abea88-f13e-4091-8d7a-77c47e5cb4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "@jitclass(trcmr_spec)\n",
    "class Trace_Reinstatement_CMR:\n",
    "\n",
    "    def __init__(self, item_count, presentation_count, parameters):\n",
    "\n",
    "        # store initial parameters\n",
    "        self.item_count = item_count\n",
    "        self.encoding_drift_rate = parameters['encoding_drift_rate']\n",
    "        self.delay_drift_rate = parameters['delay_drift_rate']\n",
    "        self.start_drift_rate = parameters['start_drift_rate']\n",
    "        self.recall_drift_rate = parameters['recall_drift_rate']\n",
    "        self.shared_support = parameters['shared_support']\n",
    "        self.item_support = parameters['item_support']\n",
    "        self.learning_rate = parameters['learning_rate']\n",
    "        self.primacy_scale = parameters['primacy_scale']\n",
    "        self.primacy_decay = parameters['primacy_decay']\n",
    "        self.stop_probability_scale = parameters['stop_probability_scale']\n",
    "        self.stop_probability_growth = parameters['stop_probability_growth']\n",
    "        self.choice_sensitivity = parameters['choice_sensitivity']\n",
    "        self.context_sensitivity = parameters['context_sensitivity']\n",
    "        self.feature_sensitivity = parameters['feature_sensitivity']\n",
    "        self.context_reinstatement = parameters['context_reinstatement']\n",
    "        self.feature_drift_rate = parameters['feature_drift_rate']\n",
    "        \n",
    "        # at the start of the list context is initialized with a state \n",
    "        # orthogonal to the pre-experimental context associated with the set of items\n",
    "        self.context = np.zeros(item_count + 2)\n",
    "        self.context[0] = 1\n",
    "        self.preretrieval_context = self.context\n",
    "        self.recall = np.zeros(item_count, dtype=int32) # recalls has at most `item_count` entries\n",
    "        self.retrieving = False\n",
    "        self.recall_total = 0\n",
    "\n",
    "        # predefine activation weighting vectors\n",
    "        self.item_weighting = np.ones(item_count+presentation_count)\n",
    "        self.context_weighting = np.ones(item_count+presentation_count)\n",
    "        self.item_weighting[item_count:] = self.learning_rate\n",
    "        self.context_weighting[item_count:] = \\\n",
    "            self.primacy_scale * np.exp(-self.primacy_decay * np.arange(presentation_count)) + 1\n",
    "        self.all_weighting = self.item_weighting * self.context_weighting\n",
    "\n",
    "        # preallocate for outcome_probabilities\n",
    "        self.probabilities = np.zeros((item_count + 1))\n",
    "\n",
    "        # predefine contextual input vectors relevant for delay_drift_rate and start_drift_rate parameters\n",
    "        self.start_context_input = np.zeros((self.item_count+2))\n",
    "        self.start_context_input[0] = 1\n",
    "        self.delay_context_input = np.zeros((self.item_count+2))\n",
    "        self.delay_context_input[-1] = 1\n",
    "\n",
    "        # initialize memory\n",
    "        # we now conceptualize it as a pairing of two stores Mfc and Mcf respectively\n",
    "        # representing feature-to-context and context-to-feature associations\n",
    "        mfc = np.eye(item_count, item_count + 2, 1) * (1 - self.learning_rate)\n",
    "        mcf = np.ones((item_count, item_count)) * self.shared_support\n",
    "        for i in range(item_count):\n",
    "            mcf[i, i] = self.item_support\n",
    "        mcf = np.hstack((np.zeros((item_count, 1)), mcf,  np.zeros((item_count, 1))))\n",
    "        self.memory = np.zeros((item_count + presentation_count, item_count * 2 + 4))\n",
    "        self.memory[:item_count,] = np.hstack((mfc, mcf))\n",
    "\n",
    "        self.norm = np.zeros(item_count + presentation_count)\n",
    "        self.norm[:item_count] = np.sqrt(np.sum(np.square(self.memory[0])))\n",
    "        self.norm[item_count:] = np.sqrt(2)\n",
    "        self.encoding_index = item_count\n",
    "\n",
    "        # base\n",
    "        self.features = np.zeros((self.item_count+2))\n",
    "        self.recall_items = np.hstack((np.eye(item_count, item_count + 2, 1), np.zeros((item_count, item_count+2))))\n",
    "        \n",
    "        # mixed cue\n",
    "        self.items = np.hstack((np.eye(item_count, item_count + 2, 1), np.eye(item_count, item_count + 2, 1)))\n",
    "        \n",
    "        # contextual unit cue\n",
    "        #self.items = np.hstack((np.zeros((item_count, item_count+2)), np.eye(item_count, item_count + 2, 1)))\n",
    "\n",
    "        # parametrized mixed cue\n",
    "        #self.items = np.hstack(\n",
    "        #    (np.eye(item_count, item_count + 2, 1), self.context_reinstatement*np.eye(item_count,item_count + 2, 1)))\n",
    "        \n",
    "        #self.items /= np.sqrt(np.sum(np.square(self.items[0])))\n",
    "\n",
    "    def experience(self, experiences):\n",
    "\n",
    "        for i in range(len(experiences)):\n",
    "\n",
    "            # configure contextual representation for trace\n",
    "            self.update_context(self.encoding_drift_rate, experiences[i])\n",
    "            self.memory[self.encoding_index, self.item_count+2:] = self.context\n",
    "\n",
    "            # configure feature representation for trace\n",
    "            self.update_features(self.feature_drift_rate, experiences[i])\n",
    "            self.memory[self.encoding_index, :self.item_count+2] = self.features\n",
    "\n",
    "            self.encoding_index += 1\n",
    "\n",
    "    def update_features(self, drift_rate, experience):\n",
    "\n",
    "        probe = experience.copy() \n",
    "        probe[:self.item_count+2] *= 0 #TODO: exclude if I'm including C information in cue\n",
    "        feature_input = self.echo(probe)[:self.item_count + 2]\n",
    "        feature_input = feature_input / np.sqrt(np.sum(np.square(feature_input))) # norm to length 1\n",
    "\n",
    "        self.features = experience[:self.item_count+2]\n",
    "        rho = np.sqrt(1 + np.square(drift_rate) * (np.square(self.features * feature_input) - 1)) - (\n",
    "                drift_rate * (self.features * feature_input))\n",
    "        self.features = (rho * self.features) + (drift_rate * feature_input)\n",
    "        self.features = self.features / np.sqrt(np.sum(np.square(self.features)))\n",
    "\n",
    "    def update_context(self, drift_rate, experience):\n",
    "\n",
    "        # first pre-experimental or initial context is retrieved\n",
    "        if len(experience) == self.item_count * 2 + 4:\n",
    "            probe = experience.copy() \n",
    "            probe[self.item_count+2:] *= self.context_reinstatement\n",
    "            context_input = self.echo(probe)[self.item_count + 2:]\n",
    "            context_input = context_input / np.sqrt(np.sum(np.square(context_input))) # norm to length 1\n",
    "        else:\n",
    "            context_input = experience\n",
    "\n",
    "        # updated context is sum of context and input, modulated by rho to have len 1 and some drift_rate\n",
    "        rho = np.sqrt(1 + np.square(drift_rate) * (np.square(self.context * context_input) - 1)) - (\n",
    "                drift_rate * (self.context * context_input))\n",
    "        self.context = (rho * self.context) + (drift_rate * context_input)\n",
    "        self.context = self.context / np.sqrt(np.sum(np.square(self.context)))\n",
    "\n",
    "    def echo(self, probe):\n",
    "        return np.dot(self.activations(probe), self.memory[:self.encoding_index])\n",
    "\n",
    "    def activations(self, probe, probe_norm=1.0):\n",
    "\n",
    "        activation = np.dot(self.memory[:self.encoding_index], probe) / (\n",
    "             self.norm[:self.encoding_index] * probe_norm)\n",
    "\n",
    "        # weight activations based on whether probe contains item or contextual features or both\n",
    "        if np.any(probe[:self.item_count + 2]): # if probe is an item feature cue as during contextual retrieval\n",
    "            if np.any(probe[self.item_count + 2:]): # if probe is (also) a contextual cue as during item retrieval\n",
    "                # both mfc and mcf weightings, see below\n",
    "                activation *= self.all_weighting[:self.encoding_index]\n",
    "            else:\n",
    "                # mfc weightings - scale by gamma for each experimental trace\n",
    "                activation *= self.item_weighting[:self.encoding_index]\n",
    "            activation = np.power(activation, self.context_sensitivity)\n",
    "        else:\n",
    "            # mcf weightings - scale by primacy/attention function based on experience position\n",
    "            activation *= self.context_weighting[:self.encoding_index]\n",
    "            if self.feature_sensitivity != 1.0:\n",
    "                activation = np.power(activation, self.feature_sensitivity)\n",
    "            else:\n",
    "                activation = np.power(activation, self.context_sensitivity)\n",
    "            \n",
    "        return activation\n",
    "\n",
    "    def outcome_probabilities(self):\n",
    "        \n",
    "        self.probabilities[0] = min(self.stop_probability_scale * np.exp(\n",
    "            self.recall_total * self.stop_probability_growth), 1.0 - (\n",
    "                 (self.item_count-self.recall_total) * 10e-7))\n",
    "        self.probabilities[1:] = 10e-7\n",
    "\n",
    "        if self.probabilities[0] < (1.0 - ((self.item_count-self.recall_total) * 10e-7)):\n",
    "\n",
    "            # measure activation for each item\n",
    "            activation_cue = np.hstack((np.zeros(self.item_count + 2), self.context))\n",
    "            activation = self.echo(activation_cue)[1:self.item_count+1]\n",
    "\n",
    "            # already recalled items have zero activation\n",
    "            activation[self.recall[:self.recall_total]] = 0\n",
    "            \n",
    "            # recall probability is a function of activation\n",
    "            if np.sum(activation) > 0:\n",
    "                activation = np.power(activation, self.choice_sensitivity)\n",
    "                self.probabilities[1:] = (1-self.probabilities[0]) * activation / np.sum(activation)\n",
    "        \n",
    "        return self.probabilities\n",
    "\n",
    "    def free_recall(self, steps=None):\n",
    "\n",
    "        # some pre-list context is reinstated before initiating recall\n",
    "        if not self.retrieving:\n",
    "            self.recall = np.zeros(self.item_count, dtype=int32)\n",
    "            self.recall_total = 0\n",
    "            self.preretrieval_context = self.context\n",
    "            self.update_context(self.delay_drift_rate, self.delay_context_input)\n",
    "            self.update_context(self.start_drift_rate, self.start_context_input)\n",
    "            self.retrieving = True\n",
    "            \n",
    "        # number of items to retrieve is infinite if steps is unspecified\n",
    "        if steps is None:\n",
    "            steps = self.item_count - self.recall_total\n",
    "        steps = self.recall_total + steps\n",
    "\n",
    "        # at each recall attempt\n",
    "        while self.recall_total < steps:\n",
    "\n",
    "            # the current state of context is used as a retrieval cue to \n",
    "            # attempt recall of a studied item compute outcome probabilities \n",
    "            # and make choice based on distribution\n",
    "            outcome_probabilities = self.outcome_probabilities()\n",
    "            if np.any(outcome_probabilities[1:]):\n",
    "                choice = np.sum(\n",
    "                    np.cumsum(outcome_probabilities) < np.random.rand(), dtype=int32)\n",
    "            else:\n",
    "                choice = 0\n",
    "\n",
    "            # resolve and maybe store outcome\n",
    "            # we stop recall if no choice is made (0)\n",
    "            if choice == 0:\n",
    "                self.retrieving = False\n",
    "                self.context = self.preretrieval_context\n",
    "                break\n",
    "            self.recall[self.recall_total] = choice - 1\n",
    "            self.recall_total += 1\n",
    "            self.update_context(self.recall_drift_rate, self.recall_items[choice - 1])\n",
    "        return self.recall[:self.recall_total]\n",
    "    \n",
    "    def force_recall(self, choice=None):\n",
    "\n",
    "        if not self.retrieving:\n",
    "            self.recall = np.zeros(self.item_count, dtype=int32)\n",
    "            self.recall_total = 0\n",
    "            self.preretrieval_context = self.context\n",
    "            self.update_context(self.delay_drift_rate, self.delay_context_input)\n",
    "            self.update_context(self.start_drift_rate, self.start_context_input)\n",
    "            self.retrieving = True\n",
    "\n",
    "        if choice is None:\n",
    "            pass\n",
    "        elif choice > 0:\n",
    "            self.recall[self.recall_total] = choice - 1\n",
    "            self.recall_total += 1\n",
    "            self.update_context(\n",
    "                self.recall_drift_rate, self.recall_items[choice - 1])\n",
    "        else:\n",
    "            self.retrieving = False\n",
    "            self.context = self.preretrieval_context\n",
    "        return self.recall[:self.recall_total]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
