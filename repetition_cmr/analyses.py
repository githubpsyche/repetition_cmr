# AUTOGENERATED! DO NOT EDIT! File to edit: notebooks/analyses/Study_Phase_Retrieval_Effect.ipynb (unless otherwise specified).

__all__ = ['repetition_contiguity', 'recall_by_all_study_positions', 'lag_crp', 'spc', 'recall_probability_by_lag',
           'df_recall_probability_by_lag', 'lag_crp']

# Cell

from numba import njit
import numpy as np

@njit(nogil=True)
def repetition_contiguity(trials, presentations, lag_threshold = 3, max_repeats = 2):

    list_length = len(presentations[0])
    lag_range = list_length - 1
    total_actual_lags = np.zeros((max_repeats, lag_range * 2 + 1)) # extended dimension to split by pres positions
    total_possible_lags = np.zeros((max_repeats, lag_range * 2 + 1))
    terminus = np.sum(trials != 0, axis=1) # number of recalls per trial
    recall_by_study_position = recall_by_all_study_positions(trials, presentations, max_repeats)

    for trial_index in range(len(trials)):
        previous_item = 0
        item_count = np.max(presentations[trial_index]) + 1
        possible_items = np.arange(item_count) # initial pool of possible recalls, 1-indexed
        possible_positions = np.zeros((item_count, max_repeats), dtype=np.int32)

        # we track possible positions using presentations and alt_presentations
        for item in range(item_count):
            pos = np.nonzero(presentations[trial_index] == item)[0] + 1
            possible_positions[item, :len(pos)] = pos

        for recall_index in range(terminus[trial_index]):

            current_item = presentations[trial_index][trials[trial_index, recall_index]-1]

            # track possible and actual lags;
            # focus only on transitions from items with > 1 study positions
            # and only when those multiple study positions have lag over lag
            if recall_index > 0 and np.count_nonzero(
                possible_positions[previous_item]) > 1 and (
                possible_positions[previous_item][1] - possible_positions[previous_item][0] >= lag_threshold):

                # item indices don't help track lags anymore
                # so more complex calculation needed to identify possible lags given previous item
                current_index = np.nonzero(possible_items==current_item)[0]

                index = 0
                for x in range(len(recall_by_study_position)):
                    for y in range(len(recall_by_study_position)):
                        if possible_positions[previous_item, y] > 0:

                            possible_lags = possible_positions[
                                possible_items, x] - possible_positions[previous_item, y]

                            # if tracked position is 0, then we don't actually want to count it in our lags
                            possible_lags[possible_positions[possible_items, x] == 0] = 0

                            # we track actual lag at each iteration
                            actual_lag = possible_lags[current_index] + lag_range
                            total_actual_lags[y][actual_lag] += 1

                            # we track possible lag at each iteration
                            possible_lags += lag_range
                            total_possible_lags[y][possible_lags] += 1

                        index += 1

            # update pool to exclude recalled item (updated to still identify 1-indexed item)
            previous_item = current_item
            possible_items = possible_items[possible_items != previous_item]


    # small correction to avoid nans and commit to excluding multiply-tracked single presentations
    total_actual_lags[:, lag_range] = 0
    for i in range(max_repeats):
        total_possible_lags[i][total_actual_lags[i]==0] += 1

    return total_actual_lags/total_possible_lags

# Cell
from numba import njit
import numpy as np

@njit(nogil=True)
def recall_by_all_study_positions(recall_by_first_study_position, presentations, max_repeats=3):

    trials_shape = np.shape(recall_by_first_study_position)
    result = np.zeros(
            (max_repeats, trials_shape[0], trials_shape[1]), dtype=np.int32)

    for trial_index in range(len(recall_by_first_study_position)):

        trial = recall_by_first_study_position[trial_index]
        presentation = presentations[trial_index]

        for recall_index in range(len(trial)):

            if trial[recall_index] == 0:
                continue

            presentation_positions = np.nonzero(
                presentation[trial[recall_index] - 1] == presentation)[0] + 1

            result[:len(presentation_positions), trial_index, recall_index] = presentation_positions

    return result

# Cell

from numba import njit
import numpy as np

#TODO: test on Howard Kahana 2005 dataset
@njit(nogil=True)
def lag_crp(trials, presentations, max_repeats=2):

    list_length = len(presentations[0])
    lag_range = list_length - 1
    total_actual_lags = np.zeros(lag_range * 2 + 1)
    total_possible_lags = np.zeros(lag_range * 2 + 1)
    terminus = np.sum(trials != 0, axis=1) # number of recalls per trial
    recall_by_study_position = recall_by_all_study_positions(trials, presentations, max_repeats)

    for trial_index in range(len(trials)):

        previous_item = 0
        item_count = np.max(presentations[trial_index]) + 1
        possible_items = np.arange(item_count) # initial pool of possible recalls, 1-indexed
        possible_positions = np.zeros((item_count, max_repeats), dtype=np.int32)

        # we track possible positions using presentations and alt_presentations
        for item in range(item_count):
            pos = np.nonzero(presentations[trial_index] == item)[0] + 1
            possible_positions[item, :len(pos)] = pos

        for recall_index in range(terminus[trial_index]):

            current_item = presentations[trial_index][trials[trial_index, recall_index]-1]

            # track possible and actual lags
            if recall_index > 0:

                # item indices don't help track lags anymore
                # so more complex calculation needed to identify possible lags given previous item
                current_index = np.nonzero(possible_items==current_item)[0]
                possible_lags = np.zeros((len(recall_by_study_position) ** 2, len(possible_items)), dtype=np.int32)

                index = 0
                for x in range(len(recall_by_study_position)):
                    for y in range(len(recall_by_study_position)):
                        if possible_positions[previous_item, y] > 0:

                            possible_lags[index] = possible_positions[
                                possible_items, x] - possible_positions[previous_item, y]

                            # if tracked position is 0, then we don't actually want to count it in our lags
                            possible_lags[index][possible_positions[possible_items, x] == 0] = 0

                        index += 1

                possible_lags += lag_range
                total_actual_lags[possible_lags[:, current_index].flatten()] += 1
                total_possible_lags[possible_lags.flatten()] += 1


            # update pool to exclude recalled item (updated to still identify 1-indexed item)
            previous_item = current_item
            possible_items = possible_items[possible_items != previous_item]

    # small correction to avoid nans and commit to excluding multiply-tracked single presentations
    total_actual_lags[lag_range] = 0
    total_possible_lags[total_actual_lags==0] += 1

    return total_actual_lags/total_possible_lags

# Cell

from numba import njit
import numpy as np

@njit(nogil=True)
def spc(trials, presentations):

    list_length = len(presentations[0])
    result = np.zeros(list_length, dtype=np.int32)
    all_study_positions = recall_by_all_study_positions(trials, presentations)

    for trial_index in range(len(trials)):
        for study_position in range(list_length):
            result[study_position] += study_position+1 in all_study_positions[:,trial_index]

    return result/len(trials)

# Cell

from numba import njit, prange
import numpy as np

@njit(nogil=True, parallel=True)
def recall_probability_by_lag(study_positions_in_recall_order, presentations, max_lag=8):

    total_presented, total_retrieved = np.zeros(max_lag+2), np.zeros(max_lag+2)

    for trial_index in prange(len(presentations)):

        # nested accumulation to ensure parallelization doesn't cause problems
        presented, retrieved = np.zeros(max_lag+2), np.zeros(max_lag+2)

        # extract sequence of presentations
        presentation = presentations[trial_index]

        # extract sequence of responses
        responses = study_positions_in_recall_order[trial_index]
        responses = responses[responses > 0]-1

        # for each studied_item in presentation, identify its presentation positions
        for studied_item in np.unique(presentation):

            # identify occurrences of item index in presentation vector
            item_occurrences = np.where(presentation == studied_item)[0]

            # convert to incremental distances
            lags = item_occurrences[1:] - item_occurrences[:-1]

            # aggregate to select bin for accumulation
            index = 0 if lags.size == 0 else np.int64(np.mean(lags))

            # accumulate
            presented[index] += 1
            retrieved[index] += item_occurrences[0] in responses

        total_presented += presented
        total_retrieved += retrieved

    return total_retrieved/total_presented

# Cell

import pandas as pd

def df_recall_probability_by_lag(trials, presentations, subject_count, trial_count, max_lag=8):

    lags = ['N/A', '0', '1-2', '3-5', '6-8']
    result = {'subject': [], 'lag': [], 'prob': []}

    for subject in range(subject_count):

        subject_result = recall_probability_by_lag(
            trials[subject*trial_count:(subject+1)*trial_count], presentations[subject*trial_count:(subject+1)*trial_count], max_lag)

        binned = np.zeros(5)
        binned[0] = subject_result[0]
        binned[1] = subject_result[1]
        binned[2] = (subject_result[2] + subject_result[3])/2
        binned[3] = (subject_result[4] + subject_result[5] + subject_result[6])/3
        binned[4] = (subject_result[7] + subject_result[8] + subject_result[9])/3

        result['subject'] += [subject+1]*len(lags)
        result['lag'] += lags
        result['prob'] += binned.tolist()

    return pd.DataFrame(result)

# Cell

from numba import njit
import numpy as np

#@njit(nogil=True)
def lag_crp(trials, presentations, max_repeats=2, mask=None, reference_positions=None):

    if mask is None:
        mask = np.ones(np.shape(trials), dtype=np.bool_)

    list_length = len(presentations[0])
    lag_range = list_length - 1
    total_actual_lags = np.zeros(lag_range * 2 + 1)
    total_possible_lags = np.zeros(lag_range * 2 + 1)
    terminus = np.sum(trials != 0, axis=1) # number of recalls per trial
    recall_by_study_position = recall_by_all_study_positions(trials, presentations, max_repeats)
    if reference_positions is None:
        reference_positions = recall_by_study_position

    for trial_index in range(len(trials)):

        previous_item = 0
        item_count = np.max(presentations[trial_index]) + 1
        possible_items = np.arange(item_count) # initial pool of possible recalls, 1-indexed
        possible_positions = np.zeros((item_count, max_repeats), dtype=np.int32)

        # we track possible positions using presentations and alt_presentations
        for item in range(item_count):
            pos = np.nonzero(presentations[trial_index] == item)[0] + 1
            possible_positions[item, :len(pos)] = pos

        for recall_index in range(terminus[trial_index]):

            current_item = presentations[trial_index][trials[trial_index, recall_index]-1]

            # track possible and actual lags
            if (recall_index > 0) and (mask[trial_index, recall_index]) and (
                reference_positions[0, trial_index, recall_index-1] != 0):

                # item indices don't help track lags anymore
                # so more complex calculation needed to identify possible lags given previous item
                current_index = np.nonzero(possible_items==current_item)[0]
                possible_lags = np.zeros((len(recall_by_study_position) ** 2, len(possible_items)), dtype=np.int32)

                index = 0
                for x in range(len(recall_by_study_position)):
                    for y in range(len(reference_positions)):
                        if reference_positions[y, trial_index, recall_index-1] > 0:

                            possible_lags[index] = possible_positions[
                                possible_items, x] - reference_positions[y, trial_index, recall_index-1]

                            # if tracked position is 0, then we don't actually want to count it in our lags
                            possible_lags[index][possible_positions[possible_items, x] == 0] = 0

                        index += 1

                possible_lags += lag_range
                total_actual_lags[possible_lags[:, current_index].flatten()] += 1
                total_possible_lags[possible_lags.flatten()] += 1


            # update pool to exclude recalled item (updated to still identify 1-indexed item)
            previous_item = current_item
            possible_items = possible_items[possible_items != previous_item]

    # small correction to avoid nans and commit to excluding multiply-tracked single presentations
    total_actual_lags[lag_range] = 0
    total_possible_lags[total_actual_lags==0] += 1

    return total_actual_lags/total_possible_lags